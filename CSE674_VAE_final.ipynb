{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "from builtins import range, input\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mnist(limit=None):\n",
    "    df = pd.read_csv('train.csv')\n",
    "    data = df.as_matrix()\n",
    "    np.random.shuffle(data)\n",
    "    X = data[:, 1:] / 255.0 # data is from 0..255\n",
    "    Y = data[:, 0]\n",
    "    if limit is not None:\n",
    "        X, Y = X[:limit], Y[:limit]\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_latent_space(vae, im_size = 28, n = 20):\n",
    "    #n:  number of pictures slided each row\n",
    "    x = np.linspace(-5, 5, n)\n",
    "    y = np.linspace(-5, 5, n)\n",
    "    im = np.empty((im_size * n, im_size * n))\n",
    "\n",
    "    Z = []\n",
    "    for i, x_ in enumerate(x):\n",
    "        for j, y_ in enumerate(y):\n",
    "            z = [x_, y_]\n",
    "            Z.append(z)\n",
    "    X_hat = vae.predict_using_Z(Z)\n",
    "\n",
    "    k = 0\n",
    "    for i, x_ in enumerate(x):\n",
    "        for j, y_ in enumerate(y):\n",
    "            x_hat = X_hat[k]\n",
    "            k += 1\n",
    "            x_hat = x_hat.reshape(im_size, im_size)\n",
    "            im[(n - i - 1) * im_size:(n - i) * im_size, j * im_size:(j + 1) * im_size] = x_hat\n",
    "    plt.imshow(im)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseLayer(object):\n",
    "    def __init__(self, M1, M2, f=tf.nn.relu):\n",
    "        self.W = tf.Variable(tf.random_normal(shape=(M1, M2)) * 2 / np.sqrt(M1))\n",
    "        self.b = tf.Variable(np.zeros(M2).astype(np.float32))\n",
    "        self.f = f\n",
    "\n",
    "    def forward(self, X):\n",
    "        with tf.device('/device:GPU:1'):\n",
    "            return self.f(tf.matmul(X, self.W) + self.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalAutoencoder:\n",
    "    def __init__(self, D, hidden_layer_sizes):\n",
    "        self.X = tf.placeholder(tf.float32, shape=(None, D))\n",
    "\n",
    "        # encoder\n",
    "        self.encoder_layers = []\n",
    "        M_in = D\n",
    "        for M_out in hidden_layer_sizes[:-1]:\n",
    "            h = DenseLayer(M_in, M_out)\n",
    "            self.encoder_layers.append(h)\n",
    "            M_in = M_out\n",
    "\n",
    "        \n",
    "        M = hidden_layer_sizes[-1]\n",
    "\n",
    "        # the encoder's final layer, it has a mean, a standard deviation for each unit\n",
    "        h_final = DenseLayer(M_in, 2 * M, f=lambda x: x)\n",
    "        self.encoder_layers.append(h_final)\n",
    "\n",
    "        # now forward till we get mean and std values\n",
    "        layer_value = self.X\n",
    "        for layer in self.encoder_layers:\n",
    "            layer_value = layer.forward(layer_value)\n",
    "        self.means = layer_value[:, :M]\n",
    "        self.stddev = tf.nn.softplus(layer_value[:, M:]) + 1e-6 # add small amount for smoothing\n",
    "        #log(exp(features) + 1) avoids zeros\n",
    "\n",
    "        # get a sample of Z\n",
    "        standard_normal = tf.contrib.distributions.Normal(\n",
    "        loc=np.zeros(M, dtype=np.float32),\n",
    "        scale=np.ones(M, dtype=np.float32)\n",
    "        )\n",
    "        e = standard_normal.sample(tf.shape(self.means)[0])\n",
    "        self.Z = e * self.stddev + self.means\n",
    "\n",
    "        # decoder\n",
    "        self.decoder_layers = []\n",
    "        M_in = M\n",
    "        for M_out in reversed(hidden_layer_sizes[:-1]):\n",
    "            h = DenseLayer(M_in, M_out)\n",
    "            self.decoder_layers.append(h)\n",
    "            M_in = M_out\n",
    "\n",
    "        # the decoder's final layer could also be sigmoid\n",
    "        h = DenseLayer(M_in, D, f=lambda x: x)\n",
    "        self.decoder_layers.append(h)\n",
    "\n",
    "        # get the reconstructed image\n",
    "        layer_value = self.Z\n",
    "        for layer in self.decoder_layers:\n",
    "            layer_value = layer.forward(layer_value)\n",
    "        logits = layer_value\n",
    "        posterior_predictive_logits = logits # save for later\n",
    "\n",
    "        # get the output\n",
    "        self.X_hat_distribution = tf.contrib.distributions.Bernoulli(logits=logits)\n",
    "\n",
    "        # take samples from X_hat\n",
    "        self.posterior_x_hat = self.X_hat_distribution.sample()\n",
    "        self.posterior_x_hat_sigmoid = tf.nn.sigmoid(logits) \n",
    "\n",
    "\n",
    "        # take random samples from Z\n",
    "        standard_normal = tf.contrib.distributions.Normal(\n",
    "          loc=np.zeros(M, dtype=np.float32),\n",
    "          scale=np.ones(M, dtype=np.float32)\n",
    "        )\n",
    "\n",
    "        Z_std = standard_normal.sample(1)\n",
    "        current_layer_value = Z_std\n",
    "        for layer in self.decoder_layers:\n",
    "            current_layer_value = layer.forward(current_layer_value)\n",
    "        logits = current_layer_value\n",
    "\n",
    "        x_hat_dist = tf.contrib.distributions.Bernoulli(logits=logits)\n",
    "        self.x_hat_sampled = x_hat_dist.sample()\n",
    "        self.x_hat_sigmoid =  tf.nn.sigmoid(logits)\n",
    "\n",
    "        # generate samples from z space\n",
    "        # only used for generating visualization\n",
    "        self.Z_input = tf.placeholder(tf.float32, shape=(None, M))\n",
    "        layer_value = self.Z_input\n",
    "        for layer in self.decoder_layers:\n",
    "            layer_value = layer.forward(layer_value)\n",
    "        logits = layer_value\n",
    "        self.x_hat_from_inputs = tf.nn.sigmoid(logits)\n",
    "\n",
    "        #now cost function\n",
    "        kl = tf.contrib.distributions.kl_divergence(tf.contrib.distributions.Normal(self.means, self.stddev), standard_normal)\n",
    "        kl = tf.reduce_sum(kl, axis =1)\n",
    "        #kl divergence kl(p1|p2) = Sum(p1*log(p1/p2)) + Sum(1-p1 *log(1-p1/1-p2))\n",
    "        \n",
    "        lle = tf.reduce_sum(self.X_hat_distribution.log_prob(self.X),1 )\n",
    "        #gives the log(probability mass function for X, given Zs)\n",
    "        #elbo term 1\n",
    "        \n",
    "        self.elbo = tf.reduce_sum(lle - kl)\n",
    "        self.train_op = tf.train.AdamOptimizer(learning_rate=0.001).minimize(-self.elbo)\n",
    "\n",
    "        # session\n",
    "        self.init_op = tf.global_variables_initializer()\n",
    "        self.sess = tf.InteractiveSession(config=tf.ConfigProto(allow_soft_placement=True))\n",
    "        self.sess.run(self.init_op)\n",
    "\n",
    "\n",
    "    def fit(self, X, epochs=2, batch_sz=64):\n",
    "        costs = []\n",
    "        n_batches = len(X) // batch_sz\n",
    "        print(\"n_batches:\", n_batches)\n",
    "        for i in range(epochs):\n",
    "            print(\"epoch:\", i)\n",
    "            np.random.shuffle(X)\n",
    "            for j in range(n_batches):\n",
    "                batch = X[j*batch_sz:(j+1)*batch_sz]\n",
    "                _, c, = self.sess.run((self.train_op, self.elbo), feed_dict={self.X: batch})\n",
    "                c /= batch_sz \n",
    "                costs.append(-c)\n",
    "                if j % 100 == 0:\n",
    "                    print(\"iter: %d, cost: %.3f\" % (j, c))\n",
    "        plt.plot(costs)\n",
    "        plt.show()\n",
    "\n",
    "    def get_means_of_Z(self, X):\n",
    "        return self.sess.run(\n",
    "          self.means,\n",
    "          feed_dict={self.X: X}\n",
    "        )\n",
    "\n",
    "    def predict_using_Z(self, Z):\n",
    "        return self.sess.run(\n",
    "          self.x_hat_from_inputs,\n",
    "          feed_dict={self.Z_input: Z}\n",
    "        )\n",
    "\n",
    "    def predict_using_X(self, X):\n",
    "        return self.sess.run(self.posterior_x_hat, feed_dict={self.X: X})\n",
    "\n",
    "    def predict_using_random_Z(self):\n",
    "        return self.sess.run((self.x_hat_sampled, self.x_hat_sigmoid))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py:1711: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_batches: 656\n",
      "epoch: 0\n",
      "iter: 0, cost: -1386.780\n",
      "iter: 100, cost: -205.113\n",
      "iter: 200, cost: -196.397\n",
      "iter: 300, cost: -187.727\n",
      "iter: 400, cost: -191.522\n",
      "iter: 500, cost: -185.339\n",
      "iter: 600, cost: -180.920\n",
      "epoch: 1\n",
      "iter: 0, cost: -186.126\n",
      "iter: 100, cost: -173.414\n",
      "iter: 200, cost: -160.988\n",
      "iter: 300, cost: -160.528\n",
      "iter: 400, cost: -180.762\n",
      "iter: 500, cost: -164.403\n",
      "iter: 600, cost: -166.987\n",
      "epoch: 2\n",
      "iter: 0, cost: -170.863\n",
      "iter: 100, cost: -161.951\n",
      "iter: 200, cost: -174.498\n",
      "iter: 300, cost: -163.127\n",
      "iter: 400, cost: -164.175\n",
      "iter: 500, cost: -155.652\n",
      "iter: 600, cost: -161.520\n",
      "epoch: 3\n",
      "iter: 0, cost: -171.678\n",
      "iter: 100, cost: -163.859\n",
      "iter: 200, cost: -160.691\n",
      "iter: 300, cost: -152.222\n",
      "iter: 400, cost: -156.577\n",
      "iter: 500, cost: -160.467\n",
      "iter: 600, cost: -157.795\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-77169f940fdf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mmnist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-22-77169f940fdf>\u001b[0m in \u001b[0;36mmnist\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mvae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariationalAutoencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-1e83138059b7>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, epochs, batch_sz)\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_sz\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_sz\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melbo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m                 \u001b[0mc\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mbatch_sz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                 \u001b[0mcosts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def mnist():\n",
    "    X, Y = get_mnist()\n",
    "    # rectifying to binary digits\n",
    "    X = (X > 0.5).astype(np.float32)\n",
    "\n",
    "    vae = VariationalAutoencoder(784, [400, 100, 10, 2])\n",
    "    vae.fit(X, epochs =10)\n",
    "    n_samples = 10\n",
    "    \n",
    "    # reconstruction\n",
    "    for j in range(n_samples) :\n",
    "        i = np.random.choice(len(X))\n",
    "        x = X[i]\n",
    "        im = vae.predict_using_X([x]).reshape(28, 28)\n",
    "        plt.figure()\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.imshow(x.reshape(28, 28), cmap='gray')\n",
    "        plt.title(\"Original\")\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.imshow(im, cmap='gray')\n",
    "        plt.title(\"Sampled\")\n",
    "        plt.show()\n",
    "\n",
    "    #sample from Z space\n",
    "    for j in range(n_samples) :\n",
    "        _, im_sigmoid = vae.predict_using_random_Z()\n",
    "        plt.figure()\n",
    "        plt.imshow(im_sigmoid.reshape(28,28), cmap='gray')\n",
    "        plt.title(\"Randomly sampled images from latent space\")\n",
    "        plt.show()\n",
    "    \n",
    "    #plot the latent space\n",
    "    plot_latent_space(vae)\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
